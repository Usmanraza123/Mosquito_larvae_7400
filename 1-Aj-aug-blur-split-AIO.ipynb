{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f65558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the main notebook we are using for augmentation such as blurring, light exposures, Spliting and making copies of augmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5705fefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/esidserver/miniforge3/envs/tf/lib/python3.11/site-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.7' (you have '2.0.5'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import tempfile\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "\n",
    "def set_global_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "def create_augmented_dataset(\n",
    "    source_dir,\n",
    "    output_dir,\n",
    "    split_ratios=(0.7, 0.20, 0.10),\n",
    "    seed=42,\n",
    "    augment_per_image=5,\n",
    "    image_size=(224, 224)\n",
    "):\n",
    "    set_global_seed(seed)\n",
    "\n",
    "    source_dir = Path(source_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    tmp_dir = Path(tempfile.mkdtemp())\n",
    "    print(f\"Temporary split directory: {tmp_dir}\")\n",
    "\n",
    "    classes = [d.name for d in source_dir.iterdir() if d.is_dir()]\n",
    "    splits = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # Create softlinked split directory\n",
    "    for cls in classes:\n",
    "        images = list((source_dir / cls).glob(\"*\"))\n",
    "        rng.shuffle(images)\n",
    "\n",
    "        n = len(images)\n",
    "        n_train = int(split_ratios[0] * n)\n",
    "        n_val = int(split_ratios[1] * n)\n",
    "\n",
    "        split_data = {\n",
    "            \"train\": images[:n_train],\n",
    "            \"val\": images[n_train:n_train + n_val],\n",
    "            \"test\": images[n_train + n_val:]\n",
    "        }\n",
    "\n",
    "        for split in splits:\n",
    "            split_path = tmp_dir / split / cls\n",
    "            split_path.mkdir(parents=True, exist_ok=True)\n",
    "            for img in split_data[split]:\n",
    "                os.symlink(os.path.abspath(img), split_path / img.name)\n",
    "\n",
    "    # Perform augmentation\n",
    "    for split in splits:\n",
    "        for cls in classes:\n",
    "            split_path = tmp_dir / split / cls\n",
    "            images = list(split_path.glob(\"*\"))\n",
    "\n",
    "            save_dir = output_dir / split / cls\n",
    "            save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            for img_index, img_path in enumerate(images):\n",
    "                img = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "                base_name = img_path.stem\n",
    "\n",
    "                # Save original resized\n",
    "                orig_resize = A.Resize(height=image_size[1], width=image_size[0])\n",
    "                orig_img = orig_resize(image=img)[\"image\"]\n",
    "                Image.fromarray(orig_img).save(save_dir / f\"{base_name}_orig.jpg\")\n",
    "\n",
    "                for i in range(augment_per_image):\n",
    "                    # Create deterministic per-image-augmentation seed\n",
    "                    aug_seed = seed + hash((img_path.name, i)) % 10_000_000\n",
    "\n",
    "                    # Set deterministic random seed for this image\n",
    "                    set_global_seed(aug_seed)\n",
    "\n",
    "                    # Define Albumentations transform\n",
    "                    transform = A.Compose([\n",
    "                        A.MotionBlur(blur_limit=(3, 15), p=1.0),\n",
    "                        A.RandomBrightnessContrast(brightness_limit=0.4, contrast_limit=0.3, p=1.0),\n",
    "                        A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=1.0),\n",
    "                        A.Resize(height=image_size[1], width=image_size[0])\n",
    "                    ])\n",
    "\n",
    "                    augmented = transform(image=img)\n",
    "                    aug_img = augmented[\"image\"]\n",
    "                    Image.fromarray(aug_img).save(save_dir / f\"{base_name}_aug{i+1}.jpg\")\n",
    "\n",
    "    print(f\"Augmented dataset saved to: {output_dir}\")\n",
    "    print(f\"Temporary symlink split in: {tmp_dir} (can delete manually after use)\")\n",
    "    return tmp_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58c2ccf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporary split directory: /tmp/tmpm35nti4u\n",
      "Augmented dataset saved to: /home/esidserver/datasets/1-original-dataset_split1\n",
      "Temporary symlink split in: /tmp/tmpm35nti4u (can delete manually after use)\n",
      "Temporary split directory: /tmp/tmpul3qv7o3\n",
      "Augmented dataset saved to: /home/esidserver/datasets/1-original-dataset_split2\n",
      "Temporary symlink split in: /tmp/tmpul3qv7o3 (can delete manually after use)\n",
      "Temporary split directory: /tmp/tmpp6deq8fp\n",
      "Augmented dataset saved to: /home/esidserver/datasets/1-original-dataset_split3\n",
      "Temporary symlink split in: /tmp/tmpp6deq8fp (can delete manually after use)\n",
      "Temporary split directory: /tmp/tmpnw698sw7\n",
      "Augmented dataset saved to: /home/esidserver/datasets/1-original-dataset_split4\n",
      "Temporary symlink split in: /tmp/tmpnw698sw7 (can delete manually after use)\n",
      "Temporary split directory: /tmp/tmpjthzw20s\n",
      "Augmented dataset saved to: /home/esidserver/datasets/1-original-dataset_split5\n",
      "Temporary symlink split in: /tmp/tmpjthzw20s (can delete manually after use)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "for split_number in range(1, 6):\n",
    "    base_seed = 12345 + split_number\n",
    "    rng = random.Random(base_seed)\n",
    "    seed = rng.randint(0, 2**32 - 1)\n",
    "\n",
    "    source_dir = \"/home/esidserver/datasets/1-original-dataset\"\n",
    "    create_augmented_dataset(\n",
    "        source_dir=source_dir,\n",
    "        output_dir=source_dir + '_split' + str(split_number),\n",
    "        split_ratios=(0.7, 0.2, 0.1),\n",
    "        seed=seed,\n",
    "        augment_per_image=5\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
