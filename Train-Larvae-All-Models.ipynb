{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "601ce859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Cell started at: 2025-07-30 21:33:45\n",
      "âœ… Cell finished in 2.91 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import wandb\n",
    "import torch\n",
    "import os\n",
    "import pickle\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import timm\n",
    "import ultralytics\n",
    "from typing import Dict, List, Tuple, Any\n",
    "\n",
    "# Torch imports\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "from torchvision.models import (\n",
    "    vgg16, vgg19, mobilenet_v2, densenet121, inception_v3, \n",
    "    efficientnet_b0, efficientnet_b3, efficientnet_b7,\n",
    "    resnet50,  \n",
    "    VGG16_Weights, VGG19_Weights, MobileNet_V2_Weights, \n",
    "    DenseNet121_Weights, Inception_V3_Weights, \n",
    "    EfficientNet_B0_Weights, EfficientNet_B3_Weights, \n",
    "    EfficientNet_B7_Weights,\n",
    "    ResNet50_Weights  # Add ResNet50 weights\n",
    ")\n",
    "SAMPLE_FRACTION = 1\n",
    "PROJECT_NAME = \"MosquitoLarvae-Classification-All3\"\n",
    "EPOCH1 = 50\n",
    "EPOCH2 = 200\n",
    "PATIENCE1 = 10\n",
    "PATIENCE2 = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebfd5e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Cell started at: 2025-07-30 21:33:50\n",
      "âœ… Cell finished in 0.00 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class WandbLogger:\n",
    "    def __init__(self, local_dir: str = './wandb_logs'):\n",
    "        \"\"\"\n",
    "        Initialize a robust wandb logger with local backup\n",
    "        \n",
    "        Args:\n",
    "            local_dir (str): Directory to store local logs\n",
    "        \"\"\"\n",
    "        self.local_dir = local_dir\n",
    "        \n",
    "        # Create local logging directory\n",
    "        os.makedirs(self.local_dir, exist_ok=True)\n",
    "        \n",
    "        # Tracking for local logs\n",
    "        self.current_run_name = None\n",
    "        self.logs = []\n",
    "    \n",
    "    def _save_local_log(self, log_data: Dict[str, Any]):\n",
    "        \"\"\"\n",
    "        Save log data locally\n",
    "        \n",
    "        Args:\n",
    "            log_data (Dict): Log data to save\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Generate unique filename\n",
    "            import pandas as pd\n",
    "            timestamp = pd.Timestamp.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"{self.current_run_name}_{timestamp}_log.pkl\"\n",
    "            filepath = os.path.join(self.local_dir, filename)\n",
    "            \n",
    "            # Save log data\n",
    "            with open(filepath, 'wb') as f:\n",
    "                pickle.dump(log_data, f)\n",
    "            \n",
    "            print(f\"Local log saved: {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving local log: {e}\")\n",
    "    \n",
    "    def _check_and_sync_logs(self, operation: str):\n",
    "        \"\"\"\n",
    "        Attempt to sync local logs before a wandb operation\n",
    "        \n",
    "        Args:\n",
    "            operation (str): The wandb operation being attempted\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # List local log files\n",
    "            local_logs = [f for f in os.listdir(self.local_dir) if f.endswith('.pkl')]\n",
    "            \n",
    "            if local_logs:\n",
    "                print(f\"Attempting to sync {len(local_logs)} local logs before {operation}\")\n",
    "                \n",
    "                # Ensure login\n",
    "                wandb.login(timeout=10)\n",
    "                \n",
    "                for log_file in local_logs:\n",
    "                    filepath = os.path.join(self.local_dir, log_file)\n",
    "                    \n",
    "                    try:\n",
    "                        # Load local log\n",
    "                        with open(filepath, 'rb') as f:\n",
    "                            log_data = pickle.load(f)\n",
    "                        \n",
    "                        # Extract run name from filename\n",
    "                        run_name = '_'.join(log_file.split('_')[:4])  # Capture full run name\n",
    "                        \n",
    "                        # Initialize run if not already initialized\n",
    "                        if not wandb.run:\n",
    "                            wandb.init(\n",
    "                                project=PROJECT_NAME,\n",
    "                                name=run_name\n",
    "                            )\n",
    "                        \n",
    "                        # Log data\n",
    "                        wandb.log(log_data)\n",
    "                        \n",
    "                        # Remove successfully synced log\n",
    "                        os.remove(filepath)\n",
    "                        print(f\"Synced and removed: {log_file}\")\n",
    "                    \n",
    "                    except Exception as sync_error:\n",
    "                        print(f\"Error syncing {log_file}: {sync_error}\")\n",
    "                \n",
    "                # Finish the run if it was temporarily initialized\n",
    "                if wandb.run:\n",
    "                    wandb.finish()\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Sync attempt before {operation} failed: {e}\")\n",
    "    \n",
    "    def init(self, run_name: str, config: Dict[str, Any] = None):\n",
    "        \"\"\"\n",
    "        Initialize wandb run with network disconnection handling and log syncing\n",
    "        \n",
    "        Args:\n",
    "            run_name (str): Name of the run\n",
    "            config (Dict, optional): Configuration dictionary\n",
    "        \n",
    "        Returns:\n",
    "            bool: Whether initialization was successful\n",
    "        \"\"\"\n",
    "        # Attempt to sync logs before initialization\n",
    "        self._check_and_sync_logs(\"init\")\n",
    "        \n",
    "        self.current_run_name = run_name\n",
    "        \n",
    "        try:\n",
    "            # Attempt wandb login\n",
    "            wandb.login(timeout=10)\n",
    "            \n",
    "            # Initialize run\n",
    "            wandb.init(\n",
    "                project=PROJECT_NAME,\n",
    "                name=run_name,\n",
    "                config=config or {}\n",
    "            )\n",
    "            return True\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Wandb initialization failed: {e}\")\n",
    "            print(\"Falling back to local logging\")\n",
    "            return False\n",
    "    \n",
    "    def log(self, log_data: Dict[str, Any], force_local: bool = False):\n",
    "        \"\"\"\n",
    "        Log data with network disconnection handling\n",
    "        \n",
    "        Args:\n",
    "            log_data (Dict): Data to log\n",
    "            force_local (bool, optional): Force local logging\n",
    "        \n",
    "        Returns:\n",
    "            bool: Whether logging was successful\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # If not force_local, try wandb logging\n",
    "            if not force_local:\n",
    "                wandb.log(log_data)\n",
    "                return True\n",
    "            \n",
    "            # Fallback to local logging\n",
    "            raise Exception(\"Forced local logging\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Wandb logging failed: {e}\")\n",
    "            print(\"Saving log locally\")\n",
    "            \n",
    "            # Save to local storage\n",
    "            self._save_local_log(log_data)\n",
    "            return False\n",
    "    \n",
    "    def finish(self):\n",
    "        \"\"\"\n",
    "        Finish the current run with network disconnection handling\n",
    "        \"\"\"\n",
    "        try:\n",
    "            wandb.finish()\n",
    "        except Exception as e:\n",
    "            print(f\"Wandb finish failed: {e}\")\n",
    "    \n",
    "    def sync_local_logs(self):\n",
    "        \"\"\"\n",
    "        Sync local logs to wandb when network is available\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Ensure login\n",
    "            wandb.login()\n",
    "            \n",
    "            # Find all local log files\n",
    "            local_logs = [f for f in os.listdir(self.local_dir) if f.endswith('.pkl')]\n",
    "            \n",
    "            for log_file in local_logs:\n",
    "                filepath = os.path.join(self.local_dir, log_file)\n",
    "                \n",
    "                try:\n",
    "                    # Load local log\n",
    "                    with open(filepath, 'rb') as f:\n",
    "                        log_data = pickle.load(f)\n",
    "                    \n",
    "                    # Extract full run name\n",
    "                    run_name = '_'.join(log_file.split('_')[:4])\n",
    "                    \n",
    "                    # Initialize run if needed\n",
    "                    if not wandb.run:\n",
    "                        wandb.init(\n",
    "                            project=PROJECT_NAME,\n",
    "                            name=run_name\n",
    "                        )\n",
    "                    \n",
    "                    # Log data\n",
    "                    wandb.log(log_data)\n",
    "                    \n",
    "                    # Remove successfully synced log\n",
    "                    os.remove(filepath)\n",
    "                    print(f\"Synced and removed: {log_file}\")\n",
    "                \n",
    "                except Exception as sync_error:\n",
    "                    print(f\"Error syncing {log_file}: {sync_error}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Sync failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57c9c21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Cell started at: 2025-07-30 21:34:01\n",
      "âœ… Cell finished in 0.00 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Configuration and Setup\n",
    "def configure_device():\n",
    "    \"\"\"\n",
    "    Detect and configure the available computing device.\n",
    "    \n",
    "    Returns:\n",
    "        torch.device: CUDA device if available, else CPU\n",
    "    \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    if device.type == 'cuda':\n",
    "        # Print GPU details\n",
    "        print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9} GB\")\n",
    "    \n",
    "    return device\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a62572b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Cell started at: 2025-07-30 21:34:39\n",
      "âœ… Cell finished in 0.00 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_data_transforms(input_size: int):\n",
    "    \"\"\"\n",
    "    Create data transformations for training and validation.\n",
    "    \n",
    "    Args:\n",
    "        input_size (int): Size to resize images\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Training and validation transforms\n",
    "    \"\"\"\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.Resize((input_size, input_size)),\n",
    "        transforms.RandomRotation(45),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    val_transforms = transforms.Compose([\n",
    "        transforms.Resize((input_size, input_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    return train_transforms, val_transforms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ec8e259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Cell started at: 2025-07-30 21:34:39\n",
      "âœ… Cell finished in 0.00 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_data_loaders(\n",
    "    base_dir: str, \n",
    "    dataset_type: str, \n",
    "    split_num: int, \n",
    "    input_size: int, \n",
    "    batch_size: int = 32,\n",
    "    sample_fraction: float = 0.01  # default onl 1% but SAMPLE_FRACTION overrules this\n",
    "):\n",
    "    \"\"\"\n",
    "    Create data loaders with optional dataset sampling.\n",
    "    \n",
    "    Args:\n",
    "        base_dir (str): Base directory of dataset\n",
    "        dataset_type (str): 'Original' or 'Augmented'\n",
    "        split_num (int): Dataset split number\n",
    "        input_size (int): Image input size\n",
    "        batch_size (int, optional): Batch size. Defaults to 32.\n",
    "        sample_fraction (float, optional): Fraction of dataset to use. Defaults to 0.01 (1%).\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Train, validation, test, and blurred test data loaders\n",
    "    \"\"\"\n",
    "    # Construct directory paths\n",
    "    split_dir = os.path.join(base_dir, f\"{dataset_type}_Larvae_Split{split_num}\")\n",
    "    train_dir = os.path.join(split_dir, 'train')\n",
    "    val_dir = os.path.join(split_dir, 'val')\n",
    "    test_dir = os.path.join(split_dir, 'test')\n",
    "    blurred_test_dir = os.path.join(split_dir, 'test-blurred')\n",
    "    \n",
    "    # Get transforms\n",
    "    train_transforms, val_transforms = get_data_transforms(input_size)\n",
    "    \n",
    "    # Create full datasets\n",
    "    train_dataset = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "    val_dataset = datasets.ImageFolder(val_dir, transform=val_transforms)\n",
    "    test_dataset = datasets.ImageFolder(test_dir, transform=val_transforms)\n",
    "    blurred_test_dataset = datasets.ImageFolder(blurred_test_dir, transform=val_transforms)\n",
    "    \n",
    "    # Sample datasets if sample_fraction < 1\n",
    "    def sample_dataset(dataset, fraction):\n",
    "        \"\"\"\n",
    "        Sample a fraction of the dataset while maintaining class balance\n",
    "        \"\"\"\n",
    "        if fraction >= 1:\n",
    "            return dataset\n",
    "        \n",
    "        # Get indices for each class\n",
    "        class_indices = {}\n",
    "        for idx, (_, label) in enumerate(dataset.samples):\n",
    "            if label not in class_indices:\n",
    "                class_indices[label] = []\n",
    "            class_indices[label].append(idx)\n",
    "        \n",
    "        # Sample balanced subset\n",
    "        sampled_indices = []\n",
    "        for label, indices in class_indices.items():\n",
    "            num_samples = max(1, int(len(indices) * fraction))\n",
    "            sampled_indices.extend(random.sample(indices, num_samples))\n",
    "        \n",
    "        return Subset(dataset, sampled_indices)\n",
    "    \n",
    "    # Sample datasets\n",
    "    train_dataset = sample_dataset(train_dataset, sample_fraction)\n",
    "    val_dataset = sample_dataset(val_dataset, sample_fraction)\n",
    "    test_dataset = sample_dataset(test_dataset, sample_fraction)\n",
    "    blurred_test_dataset = sample_dataset(blurred_test_dataset, sample_fraction)\n",
    "    \n",
    "    # Print dataset sizes\n",
    "    print(f\"Dataset Sampling for {dataset_type} Split {split_num}:\")\n",
    "    print(f\"Train dataset size: {len(train_dataset)} samples\")\n",
    "    print(f\"Validation dataset size: {len(val_dataset)} samples\")\n",
    "    print(f\"Test dataset size: {len(test_dataset)} samples\")\n",
    "    print(f\"Blurred test dataset size: {len(blurred_test_dataset)} samples\")\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    blurred_test_loader = DataLoader(blurred_test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, blurred_test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58616e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Cell started at: 2025-07-30 21:34:39\n",
      "âœ… Cell finished in 0.00 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_model(\n",
    "    model_name: str, \n",
    "    num_classes: int, \n",
    "    input_size: int, \n",
    "    device: torch.device, \n",
    "    freeze_backbone: bool = True,\n",
    "    custom_path: str = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a transfer learning model with modified classifier.\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): Name of the model\n",
    "        num_classes (int): Number of output classes\n",
    "        input_size (int): Input image size\n",
    "        device (torch.device): Device to load model on\n",
    "        freeze_backbone (bool, optional): Freeze backbone layers. Defaults to True.\n",
    "        custom_path (str, optional): Path to custom trained model\n",
    "    \n",
    "    Returns:\n",
    "        nn.Module: Modified pre-trained model\n",
    "    \"\"\"\n",
    "    # Existing model dictionary, InceptionV3, InceptionResNetV2, and the YOLOs need their customize code\n",
    "    model_dict = {\n",
    "        'VGG16': (models.vgg16, models.VGG16_Weights.IMAGENET1K_V1),\n",
    "        'VGG19': (models.vgg19, models.VGG19_Weights.IMAGENET1K_V1),\n",
    "        'MobileNet': (models.mobilenet_v2, models.MobileNet_V2_Weights.IMAGENET1K_V2),\n",
    "        'DenseNet121': (models.densenet121, models.DenseNet121_Weights.IMAGENET1K_V1),\n",
    "        'ResNet50': (models.resnet50, models.ResNet50_Weights.IMAGENET1K_V1),\n",
    "        'EfficientNetB0': (models.efficientnet_b0, models.EfficientNet_B0_Weights.IMAGENET1K_V1),\n",
    "        'EfficientNetB3': (models.efficientnet_b3, models.EfficientNet_B3_Weights.IMAGENET1K_V1),\n",
    "    }\n",
    "    \n",
    "    # YOLO model handling\n",
    "    if model_name in ['YOLOv8n-cls', 'Dilated-YOLOv8n-cls', 'YOLO11n-cls'] :\n",
    "        from ultralytics import YOLO\n",
    "        \n",
    "        # Load YOLO model\n",
    "        model = YOLO(custom_path)\n",
    "        \n",
    "        # Convert to PyTorch model\n",
    "        yolo_model = model.model\n",
    "        \n",
    "        # Create a wrapper to handle YOLO's classification model\n",
    "        class YOLOClassificationWrapper(nn.Module):\n",
    "            def __init__(self, yolo_model, num_classes, model_name):\n",
    "                super().__init__()\n",
    "                \n",
    "                # Store the original YOLO model\n",
    "                self.yolo_model = yolo_model\n",
    "                \n",
    "                # Feature extraction layer is all layers except the last classifier\n",
    "                self.feature_layer = self.yolo_model.model[:-1]\n",
    "                \n",
    "                # Original classifier is always the last layer\n",
    "                self.original_classifier = self.yolo_model.model[-1]\n",
    "                \n",
    "                # Create a new classification head that mimics the original structure\n",
    "                self.head = nn.Sequential(\n",
    "                    # Convolutional layer matching the original\n",
    "                    nn.Conv2d(256, 1280, kernel_size=1, bias=False),\n",
    "                    nn.BatchNorm2d(1280, eps=1e-05, momentum=0.1),\n",
    "                    nn.SiLU(inplace=True),\n",
    "                    \n",
    "                    # Adaptive Average Pooling\n",
    "                    nn.AdaptiveAvgPool2d(1),\n",
    "                    \n",
    "                    # Dropout (optional, can be configured)\n",
    "                    nn.Dropout(p=0.0, inplace=True),\n",
    "                    \n",
    "                    # Flatten\n",
    "                    nn.Flatten(),\n",
    "                    \n",
    "                    # Linear layer for classification\n",
    "                    nn.Linear(1280, num_classes)\n",
    "                )\n",
    "            \n",
    "            def forward(self, x):\n",
    "                # Extract features from the YOLO model\n",
    "                try:\n",
    "                    # Extract features using all layers except the last classifier\n",
    "                    features = self.feature_layer(x)\n",
    "                    \n",
    "                    # Apply the new classification head\n",
    "                    return self.head(features)\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Feature extraction error: {e}\")\n",
    "                    # If extraction fails, try a different approach\n",
    "                    features = self.yolo_model(x)\n",
    "                    \n",
    "                    # If features are still not right, raise the error\n",
    "                    if not isinstance(features, torch.Tensor):\n",
    "                        raise ValueError(\"Unable to extract features from YOLO model\")\n",
    "                    \n",
    "                    return self.head(features)\n",
    "        \n",
    "        # Wrap the YOLO model\n",
    "        model = YOLOClassificationWrapper(yolo_model, num_classes, model_name)    \n",
    "            \n",
    "        # Freeze backbone if required\n",
    "        if freeze_backbone:\n",
    "            for param in model.feature_layer.parameters():\n",
    "                param.requires_grad = False\n",
    "            \n",
    "            # Ensure head is trainable\n",
    "            for param in model.head.parameters():\n",
    "                param.requires_grad = True            \n",
    "               \n",
    "               \n",
    "    elif model_name == 'InceptionV3':\n",
    "        # Load InceptionV3 with pretrained weights\n",
    "        model = models.inception_v3(weights=models.Inception_V3_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "        # Modify the model to handle training vs. evaluation differently\n",
    "        original_forward = model.forward\n",
    "        \n",
    "        def custom_forward(x):\n",
    "            # During training, InceptionV3 returns a special output type\n",
    "            if model.training:\n",
    "                outputs = original_forward(x)\n",
    "                # Return the main logits during training\n",
    "                return outputs.logits\n",
    "            else:\n",
    "                # During evaluation, return standard output\n",
    "                return original_forward(x)\n",
    "        \n",
    "        # Replace the forward method\n",
    "        model.forward = custom_forward\n",
    "        \n",
    "        # Modify the classification head\n",
    "        num_features = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_features, num_classes)\n",
    "        \n",
    "        # Freeze backbone if required\n",
    "        if freeze_backbone:\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "            \n",
    "            # Unfreeze classification head\n",
    "            for param in model.fc.parameters():\n",
    "                param.requires_grad = True\n",
    "    \n",
    "    elif model_name == 'InceptionResNetV2':\n",
    "        import timm\n",
    "        \n",
    "        # Load TIMM model\n",
    "        model = timm.create_model('inception_resnet_v2', pretrained=True, num_classes=0)\n",
    "        \n",
    "        # Modify the model to ensure proper feature extraction and classification\n",
    "        class InceptionResNetV2Wrapper(nn.Module):\n",
    "            def __init__(self, base_model, num_classes, input_size):\n",
    "                super().__init__()\n",
    "                self.features = base_model\n",
    "                \n",
    "                # Remove any existing classification head\n",
    "                if hasattr(self.features, 'head'):\n",
    "                    delattr(self.features, 'head')\n",
    "                \n",
    "                # Global average pooling to reduce feature dimensions\n",
    "                self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "                \n",
    "                # Get number of features\n",
    "                num_features = self.features.num_features\n",
    "                \n",
    "                # Create new classification head\n",
    "                self.head = nn.Sequential(\n",
    "                    nn.Flatten(),\n",
    "                    nn.Linear(num_features, 512),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(0.5),\n",
    "                    nn.Linear(512, num_classes)\n",
    "                )\n",
    "            \n",
    "            def forward(self, x):\n",
    "                # Extract features\n",
    "                features = self.features.forward_features(x)\n",
    "                \n",
    "                # Apply global pooling\n",
    "                pooled_features = self.global_pool(features)\n",
    "                \n",
    "                # Classification\n",
    "                return self.head(pooled_features)\n",
    "        \n",
    "        # Wrap the model\n",
    "        model = InceptionResNetV2Wrapper(model, num_classes, input_size)\n",
    "        \n",
    "        # Freeze backbone if required\n",
    "        if freeze_backbone:\n",
    "            for param in model.features.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # Ensure head parameters are trainable\n",
    "        for param in model.head.parameters():\n",
    "            param.requires_grad = True                \n",
    "    else:\n",
    "        # Existing model creation logic\n",
    "        if model_name not in model_dict:\n",
    "            raise ValueError(f\"Unsupported model: {model_name}\")\n",
    "        \n",
    "        model_func, model_weights = model_dict[model_name]\n",
    "        \n",
    "        # Load model with specific weights\n",
    "        model = model_func(weights=model_weights)\n",
    "        \n",
    "        # Freeze backbone if required\n",
    "        if freeze_backbone:\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # Modify classifier based on model architecture\n",
    "        if model_name.startswith('VGG'):\n",
    "            num_features = model.classifier[0].in_features\n",
    "            model.classifier = nn.Sequential(\n",
    "                nn.Linear(num_features, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Linear(512, num_classes)\n",
    "            )\n",
    "        \n",
    "        elif model_name.startswith(('MobileNet', 'EfficientNet')):\n",
    "            num_features = model.classifier[1].in_features\n",
    "            model.classifier = nn.Linear(num_features, num_classes)\n",
    "        \n",
    "        elif model_name == 'DenseNet121':\n",
    "            num_features = model.classifier.in_features\n",
    "            model.classifier = nn.Linear(num_features, num_classes)\n",
    "                \n",
    "        elif model_name == 'ResNet50':\n",
    "            num_features = model.fc.in_features\n",
    "            model.fc = nn.Sequential(\n",
    "                nn.Linear(num_features, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Linear(512, num_classes)\n",
    "            )\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Print model information\n",
    "    print(f\"Created {model_name} model:\")\n",
    "    print(f\"Backbone frozen: {freeze_backbone}\")\n",
    "    print(f\"Input size: {input_size}\")\n",
    "    print(f\"Number of classes: {num_classes}\")\n",
    "    \n",
    "    # Count trainable parameters\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Trainable parameters: {trainable_params}\")\n",
    "    print(f\"Total parameters: {total_params}\")\n",
    "    print(f\"Trainable percentage: {100 * trainable_params / total_params:.2f}%\")\n",
    "    \n",
    "    return model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f45cedba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Cell started at: 2025-07-30 21:34:39\n",
      "âœ… Cell finished in 0.00 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(\n",
    "    model: nn.Module, \n",
    "    test_loader: DataLoader, \n",
    "    blurred_test_loader: DataLoader, \n",
    "    device: torch.device,\n",
    "    model_name: str,\n",
    "    dataset_type: str,\n",
    "    split_num: int,\n",
    "    wandb_logger: WandbLogger = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluate model performance on test and blurred test sets.\n",
    "    \"\"\"\n",
    "    # Prepare run name with Evaluation phase\n",
    "    run_name = f\"{dataset_type}_Split{split_num}_{model_name}_Evaluation\"\n",
    "    \n",
    "    # Prepare configuration for logging\n",
    "    config = {\n",
    "        \"architecture\": model_name,\n",
    "        \"dataset\": dataset_type,\n",
    "        \"split\": split_num,\n",
    "        \"stage\": \"Evaluation\"\n",
    "    }\n",
    "    \n",
    "    # Initialize wandb run with specific name\n",
    "    if wandb_logger:\n",
    "        wandb.init(\n",
    "            project=PROJECT_NAME,\n",
    "            name=run_name,\n",
    "            config=config\n",
    "        )\n",
    "    \n",
    "    try:\n",
    "        model.eval()\n",
    "        \n",
    "        def compute_detailed_metrics(loader, set_name):\n",
    "            \"\"\"\n",
    "            Compute comprehensive metrics for a given dataset\n",
    "            \"\"\"\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            class_correct = [0] * 4  # Assuming 4 classes\n",
    "            class_total = [0] * 4\n",
    "            \n",
    "            # Use torch.int to ensure integer type\n",
    "            confusion_matrix = torch.zeros(4, 4, dtype=torch.int)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in loader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    \n",
    "                    # Get predictions\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    \n",
    "                    # Update metrics\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "                    \n",
    "                    # Class-wise accuracy\n",
    "                    for t, p in zip(labels, predicted):\n",
    "                        confusion_matrix[t.long(), p.long()] += 1\n",
    "                    \n",
    "                    for i in range(4):\n",
    "                        class_mask = (labels == i)\n",
    "                        class_correct[i] += (predicted[class_mask] == labels[class_mask]).sum().item()\n",
    "                        class_total[i] += class_mask.sum().item()\n",
    "            \n",
    "            # Compute metrics\n",
    "            accuracy = 100 * correct / total\n",
    "            class_accuracies = [\n",
    "                100 * class_correct[i] / class_total[i] if class_total[i] > 0 else 0 \n",
    "                for i in range(4)\n",
    "            ]\n",
    "            \n",
    "            # Log metrics\n",
    "            if wandb_logger:\n",
    "                wandb.log({\n",
    "                    f'{set_name}_overall_accuracy': accuracy,\n",
    "                    **{f'{set_name}_class{i}_accuracy': acc for i, acc in enumerate(class_accuracies)}\n",
    "                })\n",
    "            \n",
    "            return {\n",
    "                'accuracy': accuracy,\n",
    "                'class_accuracies': class_accuracies,\n",
    "                'confusion_matrix': confusion_matrix.numpy()\n",
    "            }\n",
    "        \n",
    "        # Compute metrics for test and blurred test sets\n",
    "        test_metrics = compute_detailed_metrics(test_loader, 'test')\n",
    "        blurred_test_metrics = compute_detailed_metrics(blurred_test_loader, 'blurred_test')\n",
    "        \n",
    "        # Final logging\n",
    "        if wandb_logger:\n",
    "            wandb.log({\n",
    "                'test_accuracy': test_metrics['accuracy'],\n",
    "                'blurred_test_accuracy': blurred_test_metrics['accuracy']\n",
    "            })\n",
    "            \n",
    "            # Finish the wandb run\n",
    "            wandb.finish()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in evaluation: {e}\")\n",
    "        if wandb_logger:\n",
    "            wandb.log({\"evaluation_error\": str(e)})\n",
    "            wandb.finish()\n",
    "        raise\n",
    "    \n",
    "    # Prepare return dictionary\n",
    "    result_dict = {\n",
    "        'test_accuracy': test_metrics['accuracy'],\n",
    "        'blurred_test_accuracy': blurred_test_metrics['accuracy'],\n",
    "        'test_class_accuracies': test_metrics['class_accuracies'],\n",
    "        'blurred_test_class_accuracies': blurred_test_metrics['class_accuracies']\n",
    "    }\n",
    "    \n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "168126e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Cell started at: 2025-07-30 21:34:39\n",
      "âœ… Cell finished in 0.00 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_summary_report(results_df):\n",
    "    \"\"\"\n",
    "    Generate a comprehensive summary report of model performances.\n",
    "    \n",
    "    Args:\n",
    "        results_df (pd.DataFrame): DataFrame containing training results\n",
    "    \"\"\"\n",
    "    # Ensure matplotlib uses a backend that doesn't require a display\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    \n",
    "    # Create a directory for reports if it doesn't exist\n",
    "    os.makedirs('reports', exist_ok=True)\n",
    "    \n",
    "    # 1. Basic Statistical Summary\n",
    "    summary = results_df.groupby(['Model', 'Dataset']).agg({\n",
    "        'test_accuracy': ['mean', 'std'],\n",
    "        'blurred_test_accuracy': ['mean', 'std'],\n",
    "        'Phase2_Training_Time': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Flatten multi-level column names\n",
    "    summary.columns = [\n",
    "        'Model', 'Dataset', \n",
    "        'Test_Accuracy_Mean', 'Test_Accuracy_Std', \n",
    "        'Blurred_Test_Accuracy_Mean', 'Blurred_Test_Accuracy_Std', \n",
    "        'Avg_Training_Time'\n",
    "    ]\n",
    "    \n",
    "    # Save summary to CSV\n",
    "    summary.to_csv('reports/model_performance_summary.csv', index=False)\n",
    "    \n",
    "    # 2. Detailed Visualization\n",
    "    try:\n",
    "        # Prepare data for plotting\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        # Subplot 1: Test Accuracy Comparison\n",
    "        plt.subplot(2, 2, 1)\n",
    "        sns.barplot(\n",
    "            x='Model', \n",
    "            y='test_accuracy', \n",
    "            hue='Dataset', \n",
    "            data=results_df,\n",
    "            errorbar='sd'  # Show standard deviation\n",
    "        )\n",
    "        plt.title('Test Accuracy Across Models and Datasets')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Subplot 2: Blurred Test Accuracy Comparison\n",
    "        plt.subplot(2, 2, 2)\n",
    "        sns.barplot(\n",
    "            x='Model', \n",
    "            y='blurred_test_accuracy', \n",
    "            hue='Dataset', \n",
    "            data=results_df,\n",
    "            errorbar='sd'\n",
    "        )\n",
    "        plt.title('Blurred Test Accuracy Across Models and Datasets')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Subplot 3: Training Time Comparison\n",
    "        plt.subplot(2, 2, 3)\n",
    "        sns.boxplot(\n",
    "            x='Model', \n",
    "            y='Phase2_Training_Time', \n",
    "            hue='Dataset', \n",
    "            data=results_df\n",
    "        )\n",
    "        plt.title('Training Time Across Models and Datasets')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Subplot 4: Accuracy Difference (Test vs Blurred)\n",
    "        plt.subplot(2, 2, 4)\n",
    "        results_df['Accuracy_Difference'] = results_df['test_accuracy'] - results_df['blurred_test_accuracy']\n",
    "        sns.boxplot(\n",
    "            x='Model', \n",
    "            y='Accuracy_Difference', \n",
    "            hue='Dataset', \n",
    "            data=results_df\n",
    "        )\n",
    "        plt.title('Accuracy Drop (Test vs Blurred)')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the comprehensive plot\n",
    "        plt.savefig('reports/model_performance_comparison.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating visualizations: {e}\")\n",
    "    \n",
    "    # 3. Detailed Performance Analysis\n",
    "    try:\n",
    "        # Performance Ranking\n",
    "        performance_ranking = results_df.groupby('Model').agg({\n",
    "            'test_accuracy': 'mean',\n",
    "            'blurred_test_accuracy': 'mean'\n",
    "        }).sort_values('test_accuracy', ascending=False)\n",
    "        \n",
    "        # Save ranking\n",
    "        performance_ranking.to_csv('reports/model_performance_ranking.csv')\n",
    "        \n",
    "        # Print ranking to console\n",
    "        print(\"\\nModel Performance Ranking:\")\n",
    "        print(performance_ranking)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating performance ranking: {e}\")\n",
    "    \n",
    "    # 4. Detailed LaTeX Summary Table\n",
    "    try:\n",
    "        # Generate LaTeX table\n",
    "        latex_summary = summary.to_latex(\n",
    "            index=False, \n",
    "            float_format=\"{:.2f}\".format,\n",
    "            caption=\"Model Performance Summary\"\n",
    "        )\n",
    "        \n",
    "        with open('reports/latex_summary_table.tex', 'w') as f:\n",
    "            f.write(latex_summary)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating LaTeX summary: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c70be714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Cell started at: 2025-07-30 21:34:39\n",
      "âœ… Cell finished in 0.00 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_model(\n",
    "    model: nn.Module, \n",
    "    train_loader: DataLoader, \n",
    "    val_loader: DataLoader, \n",
    "    device: torch.device, \n",
    "    model_name: str, \n",
    "    dataset_type: str, \n",
    "    split_num: int,\n",
    "    phase: str,\n",
    "    num_epochs: int = 50, \n",
    "    patience: int = 10, \n",
    "    learning_rate: float = 1e-4,\n",
    "    wandb_logger: WandbLogger = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Train the model with comprehensive wandb logging.\n",
    "    \"\"\"\n",
    "    # Prepare run name with phase\n",
    "    run_name = f\"{dataset_type}_Split{split_num}_{model_name}_{phase}\"\n",
    "    \n",
    "    # Prepare configuration for logging\n",
    "    config = {\n",
    "        \"architecture\": model_name,\n",
    "        \"dataset\": dataset_type,\n",
    "        \"split\": split_num,\n",
    "        \"phase\": phase,\n",
    "        \"epochs\": num_epochs,\n",
    "        \"patience\": patience,\n",
    "        \"initial_learning_rate\": learning_rate\n",
    "    }\n",
    "    \n",
    "    # Use WandbLogger for initialization\n",
    "    if wandb_logger:\n",
    "        # Attempt to initialize with the specific run name\n",
    "        wandb_logger.current_run_name = run_name\n",
    "        init_success = wandb_logger.init(run_name, config)\n",
    "    \n",
    "    try:\n",
    "        # Loss and optimizer\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        # Learning rate scheduler\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, \n",
    "            mode='min', \n",
    "            factor=0.1, \n",
    "            patience=max(5, num_epochs // 10)\n",
    "        )\n",
    "        \n",
    "        # Training tracking\n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Metrics tracking\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        train_accuracies = []\n",
    "        val_accuracies = []\n",
    "        learning_rates = []\n",
    "        \n",
    "        # Actual epochs might be less due to early stopping\n",
    "        actual_epochs = 0\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            # Set model to training mode\n",
    "            model.train()\n",
    "            \n",
    "            # Training phase\n",
    "            epoch_train_loss = 0.0\n",
    "            correct_train = 0\n",
    "            total_train = 0\n",
    "            \n",
    "            for inputs, labels in train_loader:\n",
    "                # Move data to device\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Backward pass and optimize\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Tracking training metrics\n",
    "                epoch_train_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_train += labels.size(0)\n",
    "                correct_train += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Calculate training metrics\n",
    "            train_loss = epoch_train_loss / len(train_loader)\n",
    "            train_accuracy = 100 * correct_train / total_train\n",
    "            \n",
    "            # Validation phase\n",
    "            model.eval()\n",
    "            epoch_val_loss = 0.0\n",
    "            correct_val = 0\n",
    "            total_val = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in val_loader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    epoch_val_loss += loss.item()\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total_val += labels.size(0)\n",
    "                    correct_val += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Calculate validation metrics\n",
    "            val_loss = epoch_val_loss / len(val_loader)\n",
    "            val_accuracy = 100 * correct_val / total_val\n",
    "            \n",
    "            # Update learning rate scheduler\n",
    "            scheduler.step(val_loss)\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            \n",
    "            # Store metrics\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            train_accuracies.append(train_accuracy)\n",
    "            val_accuracies.append(val_accuracy)\n",
    "            learning_rates.append(current_lr)\n",
    "            \n",
    "            # Wandb logging\n",
    "            if wandb_logger:\n",
    "                wandb_logger.log({\n",
    "                    'epoch': epoch,\n",
    "                    'train_loss': train_loss,\n",
    "                    'train_accuracy': train_accuracy,\n",
    "                    'val_loss': val_loss,\n",
    "                    'val_accuracy': val_accuracy,\n",
    "                    'learning_rate': current_lr\n",
    "                })\n",
    "            \n",
    "            # Early stopping logic\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "                # Save the best model\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': best_val_loss\n",
    "                }, f'{dataset_type}_Split{split_num}_{model_name}_{phase}_best_model.pth')\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            actual_epochs += 1\n",
    "            \n",
    "            # Break if no improvement\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "        \n",
    "        # Calculate total training time\n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        # Final logging\n",
    "        if wandb_logger:\n",
    "            wandb_logger.log({\n",
    "                'total_training_time': training_time,\n",
    "                'actual_epochs': actual_epochs,\n",
    "                'best_val_loss': best_val_loss\n",
    "            })\n",
    "            \n",
    "            # Finish the wandb run\n",
    "            wandb_logger.finish()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in training: {e}\")\n",
    "        if wandb_logger:\n",
    "            wandb_logger.log({\"training_error\": str(e)})\n",
    "            wandb_logger.finish()\n",
    "        raise\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'training_time': training_time,\n",
    "        'actual_epochs': actual_epochs,\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'val_accuracies': val_accuracies,\n",
    "        'learning_rates': learning_rates\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21df4929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Cell started at: 2025-07-30 21:34:39\n",
      "âœ… Cell finished in 0.00 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    \"\"\"\n",
    "    Set random seeds for reproducibility across various libraries.\n",
    "    \n",
    "    Args:\n",
    "        seed (int, optional): Random seed value. Defaults to 42.\n",
    "    \"\"\"\n",
    "    # Python's built-in random module\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # Numpy\n",
    "    import numpy as np\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # PyTorch\n",
    "    import torch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # For multi-GPU setups\n",
    "    \n",
    "    # PyTorch reproducibility settings\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    # Optional: Set environment variable for further reproducibility\n",
    "    import os\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e56a39d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Cell started at: 2025-07-30 21:34:39\n",
      "Using device: cuda\n",
      "GPU Name: NVIDIA GeForce RTX 4090\n",
      "GPU Memory: 25.262096384 GB\n",
      "âœ… Cell finished in 0.06 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "device = configure_device()\n",
    "\n",
    "def main():\n",
    "    # Ensure reproducibility\n",
    "    set_seed()\n",
    "\n",
    "    # Configuration\n",
    "    base_dir = './datasets'\n",
    "    dataset_types = ['Original', 'Augmented']\n",
    "    splits = range(1, 6)\n",
    "    num_classes = 4\n",
    "    completed_file = 'completed_runs.json'\n",
    "\n",
    "    # Load or initialize completed runs\n",
    "    if os.path.exists(completed_file):\n",
    "        with open(completed_file, 'r') as f:\n",
    "            completed_runs = set(json.load(f))\n",
    "    else:\n",
    "        completed_runs = set()\n",
    "\n",
    "    # Initialize wandb\n",
    "    wandb_logger = WandbLogger()\n",
    "\n",
    "    # Results tracking\n",
    "    results = []\n",
    "\n",
    "    # Define models (make sure this matches other cells or consolidate)\n",
    "    models_config = [\n",
    " #       {'name': 'YOLOv8n-cls', 'input_size': 224, 'learning_rate': 0.01, 'weights': 'yolov8n-cls.pt'},\n",
    " #       {'name': 'Dilated-YOLOv8n-cls', 'input_size': 224, 'learning_rate': 0.01, 'weights': 'dilated-yolov8n-cls.pt'},\n",
    " #       {'name': 'YOLO11n-cls', 'input_size': 224, 'learning_rate': 0.01, 'weights': 'yolo11n-cls.pt'},\n",
    "        {'name': 'VGG16', 'input_size': 224, 'learning_rate': 0.001},\n",
    "        {'name': 'VGG19', 'input_size': 224, 'learning_rate': 0.001},\n",
    "        {'name': 'MobileNet', 'input_size': 224, 'learning_rate': 0.001},\n",
    "        {'name': 'DenseNet121', 'input_size': 224, 'learning_rate': 0.001},\n",
    "        {'name': 'InceptionV3', 'input_size': 299, 'learning_rate': 0.001},\n",
    "        {'name': 'ResNet50', 'input_size': 224, 'learning_rate': 0.001},\n",
    "        {'name': 'InceptionResNetV2', 'input_size': 299, 'learning_rate': 0.001},\n",
    "        {'name': 'EfficientNetB0', 'input_size': 224, 'learning_rate': 0.001},\n",
    "        {'name': 'EfficientNetB3', 'input_size': 300, 'learning_rate': 0.001},\n",
    "    ]\n",
    "    \n",
    "    for dataset_type in dataset_types:\n",
    "        for split in splits:\n",
    "            for model_config in models_config:\n",
    "                run_id = f\"{dataset_type}_Split{split}_{model_config['name']}\"\n",
    "                if run_id in completed_runs:\n",
    "                    print(f\"Skipping completed run: {run_id}\")\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    # Create data loaders\n",
    "                    train_loader, val_loader, test_loader, blurred_test_loader = create_data_loaders(\n",
    "                        base_dir,\n",
    "                        dataset_type,\n",
    "                        split,\n",
    "                        model_config['input_size'],\n",
    "                        sample_fraction=SAMPLE_FRACTION\n",
    "                    )\n",
    "\n",
    "                    custom_path = model_config['weights'] if 'YOLO' in model_config['name'] else None\n",
    "\n",
    "                    # Phase 1\n",
    "                    model_phase1 = create_model(\n",
    "                        model_config['name'],\n",
    "                        num_classes,\n",
    "                        model_config['input_size'],\n",
    "                        device,\n",
    "                        freeze_backbone=True,\n",
    "                        custom_path=custom_path\n",
    "                    )\n",
    "                    phase1_result = train_model(\n",
    "                        model_phase1,\n",
    "                        train_loader,\n",
    "                        val_loader,\n",
    "                        device,\n",
    "                        model_config['name'],\n",
    "                        dataset_type,\n",
    "                        split,\n",
    "                        phase='Transfer',\n",
    "                        num_epochs=EPOCH1,\n",
    "                        patience=PATIENCE1,\n",
    "                        learning_rate=model_config['learning_rate'],\n",
    "                        wandb_logger=wandb_logger\n",
    "                    )\n",
    "\n",
    "                    # Unfreeze all layers for Phase 2\n",
    "                    for param in model_phase1.parameters():\n",
    "                        param.requires_grad = True\n",
    "\n",
    "                    # Train the same model (fine-tune it)\n",
    "                    phase2_result = train_model(\n",
    "                        model_phase1,  # continue with the trained model\n",
    "                        train_loader,\n",
    "                        val_loader,\n",
    "                        device,\n",
    "                        model_config['name'],\n",
    "                        dataset_type,\n",
    "                        split,\n",
    "                        phase='Retrain',\n",
    "                        num_epochs=EPOCH2,\n",
    "                        patience=PATIENCE2,\n",
    "                        learning_rate=model_config['learning_rate']/10,\n",
    "                        wandb_logger=wandb_logger\n",
    "                    )\n",
    "\n",
    "                    # Evaluation\n",
    "                    eval_metrics = evaluate_model(\n",
    "                        model_phase1,\n",
    "                        test_loader,\n",
    "                        blurred_test_loader,\n",
    "                        device,\n",
    "                        model_config['name'],\n",
    "                        dataset_type,\n",
    "                        split,\n",
    "                        wandb_logger=wandb_logger\n",
    "                    )\n",
    "\n",
    "                    # Record results\n",
    "                    result_entry = {\n",
    "                        'Dataset': dataset_type,\n",
    "                        'Split': split,\n",
    "                        'Model': model_config['name'],\n",
    "                        'Phase1_Epochs': phase1_result['actual_epochs'],\n",
    "                        'Phase1_Training_Time': phase1_result['training_time'],\n",
    "                        'Phase2_Epochs': phase2_result['actual_epochs'],\n",
    "                        'Phase2_Training_Time': phase2_result['training_time'],\n",
    "                        **eval_metrics\n",
    "                    }\n",
    "                    results.append(result_entry)\n",
    "\n",
    "                    # Mark run as completed\n",
    "                    completed_runs.add(run_id)\n",
    "                    with open(completed_file, 'w') as f:\n",
    "                        json.dump(sorted(completed_runs), f, indent=2)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ Error processing {run_id}: {e}\")\n",
    "                    import traceback\n",
    "                    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "216fd611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Cell started at: 2025-07-30 21:34:39\n",
      "Skipping completed run: Original_Split1_VGG16\n",
      "Skipping completed run: Original_Split1_VGG19\n",
      "Skipping completed run: Original_Split1_MobileNet\n",
      "Skipping completed run: Original_Split1_DenseNet121\n",
      "Skipping completed run: Original_Split1_InceptionV3\n",
      "Skipping completed run: Original_Split1_ResNet50\n",
      "Skipping completed run: Original_Split1_InceptionResNetV2\n",
      "Skipping completed run: Original_Split1_EfficientNetB0\n",
      "Skipping completed run: Original_Split1_EfficientNetB3\n",
      "Skipping completed run: Original_Split2_VGG16\n",
      "Skipping completed run: Original_Split2_VGG19\n",
      "Skipping completed run: Original_Split2_MobileNet\n",
      "Skipping completed run: Original_Split2_DenseNet121\n",
      "Skipping completed run: Original_Split2_InceptionV3\n",
      "Skipping completed run: Original_Split2_ResNet50\n",
      "Skipping completed run: Original_Split2_InceptionResNetV2\n",
      "Skipping completed run: Original_Split2_EfficientNetB0\n",
      "Skipping completed run: Original_Split2_EfficientNetB3\n",
      "Skipping completed run: Original_Split3_VGG16\n",
      "Skipping completed run: Original_Split3_VGG19\n",
      "Skipping completed run: Original_Split3_MobileNet\n",
      "Skipping completed run: Original_Split3_DenseNet121\n",
      "Skipping completed run: Original_Split3_InceptionV3\n",
      "Skipping completed run: Original_Split3_ResNet50\n",
      "Skipping completed run: Original_Split3_InceptionResNetV2\n",
      "Skipping completed run: Original_Split3_EfficientNetB0\n",
      "Skipping completed run: Original_Split3_EfficientNetB3\n",
      "Skipping completed run: Original_Split4_VGG16\n",
      "Skipping completed run: Original_Split4_VGG19\n",
      "Skipping completed run: Original_Split4_MobileNet\n",
      "Skipping completed run: Original_Split4_DenseNet121\n",
      "Skipping completed run: Original_Split4_InceptionV3\n",
      "Skipping completed run: Original_Split4_ResNet50\n",
      "Skipping completed run: Original_Split4_InceptionResNetV2\n",
      "Skipping completed run: Original_Split4_EfficientNetB0\n",
      "Skipping completed run: Original_Split4_EfficientNetB3\n",
      "Skipping completed run: Original_Split5_VGG16\n",
      "Skipping completed run: Original_Split5_VGG19\n",
      "Skipping completed run: Original_Split5_MobileNet\n",
      "Skipping completed run: Original_Split5_DenseNet121\n",
      "Skipping completed run: Original_Split5_InceptionV3\n",
      "Skipping completed run: Original_Split5_ResNet50\n",
      "Skipping completed run: Original_Split5_InceptionResNetV2\n",
      "Skipping completed run: Original_Split5_EfficientNetB0\n",
      "Skipping completed run: Original_Split5_EfficientNetB3\n",
      "Skipping completed run: Augmented_Split1_VGG16\n",
      "Skipping completed run: Augmented_Split1_VGG19\n",
      "Skipping completed run: Augmented_Split1_MobileNet\n",
      "Skipping completed run: Augmented_Split1_DenseNet121\n",
      "Skipping completed run: Augmented_Split1_InceptionV3\n",
      "Skipping completed run: Augmented_Split1_ResNet50\n",
      "Skipping completed run: Augmented_Split1_InceptionResNetV2\n",
      "Skipping completed run: Augmented_Split1_EfficientNetB0\n",
      "Skipping completed run: Augmented_Split1_EfficientNetB3\n",
      "Skipping completed run: Augmented_Split2_VGG16\n",
      "Skipping completed run: Augmented_Split2_VGG19\n",
      "Skipping completed run: Augmented_Split2_MobileNet\n",
      "Skipping completed run: Augmented_Split2_DenseNet121\n",
      "Skipping completed run: Augmented_Split2_InceptionV3\n",
      "Skipping completed run: Augmented_Split2_ResNet50\n",
      "Skipping completed run: Augmented_Split2_InceptionResNetV2\n",
      "Skipping completed run: Augmented_Split2_EfficientNetB0\n",
      "Skipping completed run: Augmented_Split2_EfficientNetB3\n",
      "Skipping completed run: Augmented_Split3_VGG16\n",
      "Skipping completed run: Augmented_Split3_VGG19\n",
      "Skipping completed run: Augmented_Split3_MobileNet\n",
      "Skipping completed run: Augmented_Split3_DenseNet121\n",
      "Skipping completed run: Augmented_Split3_InceptionV3\n",
      "Skipping completed run: Augmented_Split3_ResNet50\n",
      "Skipping completed run: Augmented_Split3_InceptionResNetV2\n",
      "Skipping completed run: Augmented_Split3_EfficientNetB0\n",
      "Skipping completed run: Augmented_Split3_EfficientNetB3\n",
      "Skipping completed run: Augmented_Split4_VGG16\n",
      "Skipping completed run: Augmented_Split4_VGG19\n",
      "Skipping completed run: Augmented_Split4_MobileNet\n",
      "Skipping completed run: Augmented_Split4_DenseNet121\n",
      "Skipping completed run: Augmented_Split4_InceptionV3\n",
      "Skipping completed run: Augmented_Split4_ResNet50\n",
      "Skipping completed run: Augmented_Split4_InceptionResNetV2\n",
      "Skipping completed run: Augmented_Split4_EfficientNetB0\n",
      "Skipping completed run: Augmented_Split4_EfficientNetB3\n",
      "Skipping completed run: Augmented_Split5_VGG16\n",
      "Skipping completed run: Augmented_Split5_VGG19\n",
      "Skipping completed run: Augmented_Split5_MobileNet\n",
      "Skipping completed run: Augmented_Split5_DenseNet121\n",
      "Skipping completed run: Augmented_Split5_InceptionV3\n",
      "Skipping completed run: Augmented_Split5_ResNet50\n",
      "Dataset Sampling for Augmented Split 5:\n",
      "Train dataset size: 31338 samples\n",
      "Validation dataset size: 8946 samples\n",
      "Test dataset size: 4494 samples\n",
      "Blurred test dataset size: 4494 samples\n",
      "Created InceptionResNetV2 model:\n",
      "Backbone frozen: True\n",
      "Input size: 299\n",
      "Number of classes: 4\n",
      "Trainable parameters: 788996\n",
      "Total parameters: 55095460\n",
      "Trainable percentage: 1.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwanchp\u001b[0m (\u001b[33mwanchp-chulalongkorn-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/wanchalerm/pyNotebooks/wandb/run-20250730_213441-t4zo2q8t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/t4zo2q8t' target=\"_blank\">Augmented_Split5_InceptionResNetV2_Transfer</a></strong> to <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3' target=\"_blank\">https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/t4zo2q8t' target=\"_blank\">https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/t4zo2q8t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 12\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>actual_epochs</td><td>â–</td></tr><tr><td>best_val_loss</td><td>â–</td></tr><tr><td>epoch</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–‡â–ˆ</td></tr><tr><td>learning_rate</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–â–</td></tr><tr><td>total_training_time</td><td>â–</td></tr><tr><td>train_accuracy</td><td>â–â–„â–…â–†â–†â–†â–†â–†â–†â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>train_loss</td><td>â–ˆâ–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–â–â–â–</td></tr><tr><td>val_accuracy</td><td>â–â–„â–…â–ƒâ–â–„â–‚â–ƒâ–ƒâ–‡â–ƒâ–‡â–ˆ</td></tr><tr><td>val_loss</td><td>â–â–‚â–â–ƒâ–ƒâ–ƒâ–…â–„â–„â–‚â–ˆâ–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>actual_epochs</td><td>13</td></tr><tr><td>best_val_loss</td><td>1.255</td></tr><tr><td>epoch</td><td>12</td></tr><tr><td>learning_rate</td><td>0.0001</td></tr><tr><td>total_training_time</td><td>676.05559</td></tr><tr><td>train_accuracy</td><td>81.68677</td></tr><tr><td>train_loss</td><td>0.46306</td></tr><tr><td>val_accuracy</td><td>75.69864</td></tr><tr><td>val_loss</td><td>1.58693</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Augmented_Split5_InceptionResNetV2_Transfer</strong> at: <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/t4zo2q8t' target=\"_blank\">https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/t4zo2q8t</a><br> View project at: <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3' target=\"_blank\">https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250730_213441-t4zo2q8t/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/wanchalerm/pyNotebooks/wandb/run-20250730_214600-u33227xn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/u33227xn' target=\"_blank\">Augmented_Split5_InceptionResNetV2_Retrain</a></strong> to <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3' target=\"_blank\">https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/u33227xn' target=\"_blank\">https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/u33227xn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 68\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>actual_epochs</td><td>â–</td></tr><tr><td>best_val_loss</td><td>â–</td></tr><tr><td>epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>learning_rate</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–</td></tr><tr><td>total_training_time</td><td>â–</td></tr><tr><td>train_accuracy</td><td>â–â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>train_loss</td><td>â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>val_accuracy</td><td>â–†â–ƒâ–â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>val_loss</td><td>â–â–‚â–ˆâ–‡â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>actual_epochs</td><td>69</td></tr><tr><td>best_val_loss</td><td>0.00769</td></tr><tr><td>epoch</td><td>68</td></tr><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>total_training_time</td><td>10167.03213</td></tr><tr><td>train_accuracy</td><td>99.99681</td></tr><tr><td>train_loss</td><td>7e-05</td></tr><tr><td>val_accuracy</td><td>99.80997</td></tr><tr><td>val_loss</td><td>0.02567</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Augmented_Split5_InceptionResNetV2_Retrain</strong> at: <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/u33227xn' target=\"_blank\">https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/u33227xn</a><br> View project at: <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3' target=\"_blank\">https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250730_214600-u33227xn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/wanchalerm/pyNotebooks/wandb/run-20250731_003530-9p9mzj48</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/9p9mzj48' target=\"_blank\">Augmented_Split5_InceptionResNetV2_Evaluation</a></strong> to <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3' target=\"_blank\">https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/9p9mzj48' target=\"_blank\">https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/9p9mzj48</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>blurred_test_accuracy</td><td>â–</td></tr><tr><td>blurred_test_class0_accuracy</td><td>â–</td></tr><tr><td>blurred_test_class1_accuracy</td><td>â–</td></tr><tr><td>blurred_test_class2_accuracy</td><td>â–</td></tr><tr><td>blurred_test_class3_accuracy</td><td>â–</td></tr><tr><td>blurred_test_overall_accuracy</td><td>â–</td></tr><tr><td>test_accuracy</td><td>â–</td></tr><tr><td>test_class0_accuracy</td><td>â–</td></tr><tr><td>test_class1_accuracy</td><td>â–</td></tr><tr><td>test_class2_accuracy</td><td>â–</td></tr><tr><td>test_class3_accuracy</td><td>â–</td></tr><tr><td>test_overall_accuracy</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>blurred_test_accuracy</td><td>72.18514</td></tr><tr><td>blurred_test_class0_accuracy</td><td>43.29897</td></tr><tr><td>blurred_test_class1_accuracy</td><td>83.96396</td></tr><tr><td>blurred_test_class2_accuracy</td><td>65.41219</td></tr><tr><td>blurred_test_class3_accuracy</td><td>97.64493</td></tr><tr><td>blurred_test_overall_accuracy</td><td>72.18514</td></tr><tr><td>test_accuracy</td><td>99.9555</td></tr><tr><td>test_class0_accuracy</td><td>99.91409</td></tr><tr><td>test_class1_accuracy</td><td>99.90991</td></tr><tr><td>test_class2_accuracy</td><td>100</td></tr><tr><td>test_class3_accuracy</td><td>100</td></tr><tr><td>test_overall_accuracy</td><td>99.9555</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Augmented_Split5_InceptionResNetV2_Evaluation</strong> at: <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/9p9mzj48' target=\"_blank\">https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/9p9mzj48</a><br> View project at: <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3' target=\"_blank\">https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250731_003530-9p9mzj48/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Sampling for Augmented Split 5:\n",
      "Train dataset size: 31338 samples\n",
      "Validation dataset size: 8946 samples\n",
      "Test dataset size: 4494 samples\n",
      "Blurred test dataset size: 4494 samples\n",
      "Created EfficientNetB0 model:\n",
      "Backbone frozen: True\n",
      "Input size: 224\n",
      "Number of classes: 4\n",
      "Trainable parameters: 5124\n",
      "Total parameters: 4012672\n",
      "Trainable percentage: 0.13%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/wanchalerm/pyNotebooks/wandb/run-20250731_003545-gcuvaw1o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/gcuvaw1o' target=\"_blank\">Augmented_Split5_EfficientNetB0_Transfer</a></strong> to <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3' target=\"_blank\">https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/gcuvaw1o' target=\"_blank\">https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/gcuvaw1o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 30\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>actual_epochs</td><td>â–</td></tr><tr><td>best_val_loss</td><td>â–</td></tr><tr><td>epoch</td><td>â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>learning_rate</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–</td></tr><tr><td>total_training_time</td><td>â–</td></tr><tr><td>train_accuracy</td><td>â–â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–ˆ</td></tr><tr><td>train_loss</td><td>â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–â–â–â–‚â–â–â–</td></tr><tr><td>val_accuracy</td><td>â–â–â–‚â–„â–„â–…â–‡â–†â–„â–‚â–‡â–†â–‡â–…â–…â–†â–‡â–„â–‡â–‡â–ˆâ–‡â–ˆâ–†â–†â–‡â–‡â–‡â–…â–†â–†</td></tr><tr><td>val_loss</td><td>â–ˆâ–‡â–…â–„â–„â–ƒâ–ƒâ–ƒâ–„â–…â–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–â–‚â–â–‚â–‚â–â–‚â–‚â–ƒâ–‚â–‚</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>actual_epochs</td><td>31</td></tr><tr><td>best_val_loss</td><td>0.39859</td></tr><tr><td>epoch</td><td>30</td></tr><tr><td>learning_rate</td><td>1e-05</td></tr><tr><td>total_training_time</td><td>429.39334</td></tr><tr><td>train_accuracy</td><td>79.48178</td></tr><tr><td>train_loss</td><td>0.51079</td></tr><tr><td>val_accuracy</td><td>83.13213</td></tr><tr><td>val_loss</td><td>0.41314</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Augmented_Split5_EfficientNetB0_Transfer</strong> at: <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/gcuvaw1o' target=\"_blank\">https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/gcuvaw1o</a><br> View project at: <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3' target=\"_blank\">https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250731_003545-gcuvaw1o/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/wanchalerm/pyNotebooks/wandb/run-20250731_004257-0bx8ml5i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/0bx8ml5i' target=\"_blank\">Augmented_Split5_EfficientNetB0_Retrain</a></strong> to <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3' target=\"_blank\">https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/0bx8ml5i' target=\"_blank\">https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/0bx8ml5i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 72\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>actual_epochs</td><td>â–</td></tr><tr><td>best_val_loss</td><td>â–</td></tr><tr><td>epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>learning_rate</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–</td></tr><tr><td>total_training_time</td><td>â–</td></tr><tr><td>train_accuracy</td><td>â–â–…â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>train_loss</td><td>â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>val_accuracy</td><td>â–â–„â–…â–…â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>val_loss</td><td>â–ˆâ–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–â–ƒâ–‚â–‚â–ƒâ–â–‚â–‚â–ƒâ–â–‚â–‚â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–â–‚</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>actual_epochs</td><td>73</td></tr><tr><td>best_val_loss</td><td>0.01007</td></tr><tr><td>epoch</td><td>72</td></tr><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>total_training_time</td><td>2143.15134</td></tr><tr><td>train_accuracy</td><td>99.99043</td></tr><tr><td>train_loss</td><td>0.00036</td></tr><tr><td>val_accuracy</td><td>99.66465</td></tr><tr><td>val_loss</td><td>0.01694</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Augmented_Split5_EfficientNetB0_Retrain</strong> at: <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/0bx8ml5i' target=\"_blank\">https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/0bx8ml5i</a><br> View project at: <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3' target=\"_blank\">https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250731_004257-0bx8ml5i/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/wanchalerm/pyNotebooks/wandb/run-20250731_011843-p1gvgeoe</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/p1gvgeoe' target=\"_blank\">Augmented_Split5_EfficientNetB0_Evaluation</a></strong> to <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3' target=\"_blank\">https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/p1gvgeoe' target=\"_blank\">https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/p1gvgeoe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>blurred_test_accuracy</td><td>â–</td></tr><tr><td>blurred_test_class0_accuracy</td><td>â–</td></tr><tr><td>blurred_test_class1_accuracy</td><td>â–</td></tr><tr><td>blurred_test_class2_accuracy</td><td>â–</td></tr><tr><td>blurred_test_class3_accuracy</td><td>â–</td></tr><tr><td>blurred_test_overall_accuracy</td><td>â–</td></tr><tr><td>test_accuracy</td><td>â–</td></tr><tr><td>test_class0_accuracy</td><td>â–</td></tr><tr><td>test_class1_accuracy</td><td>â–</td></tr><tr><td>test_class2_accuracy</td><td>â–</td></tr><tr><td>test_class3_accuracy</td><td>â–</td></tr><tr><td>test_overall_accuracy</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>blurred_test_accuracy</td><td>90.74321</td></tr><tr><td>blurred_test_class0_accuracy</td><td>86.2543</td></tr><tr><td>blurred_test_class1_accuracy</td><td>89.0991</td></tr><tr><td>blurred_test_class2_accuracy</td><td>98.83513</td></tr><tr><td>blurred_test_class3_accuracy</td><td>88.94928</td></tr><tr><td>blurred_test_overall_accuracy</td><td>90.74321</td></tr><tr><td>test_accuracy</td><td>99.71073</td></tr><tr><td>test_class0_accuracy</td><td>99.82818</td></tr><tr><td>test_class1_accuracy</td><td>99.0991</td></tr><tr><td>test_class2_accuracy</td><td>100</td></tr><tr><td>test_class3_accuracy</td><td>99.90942</td></tr><tr><td>test_overall_accuracy</td><td>99.71073</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Augmented_Split5_EfficientNetB0_Evaluation</strong> at: <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/p1gvgeoe' target=\"_blank\">https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/p1gvgeoe</a><br> View project at: <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3' target=\"_blank\">https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250731_011843-p1gvgeoe/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Sampling for Augmented Split 5:\n",
      "Train dataset size: 31338 samples\n",
      "Validation dataset size: 8946 samples\n",
      "Test dataset size: 4494 samples\n",
      "Blurred test dataset size: 4494 samples\n",
      "Created EfficientNetB3 model:\n",
      "Backbone frozen: True\n",
      "Input size: 300\n",
      "Number of classes: 4\n",
      "Trainable parameters: 6148\n",
      "Total parameters: 10702380\n",
      "Trainable percentage: 0.06%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/wanchalerm/pyNotebooks/wandb/run-20250731_011849-cjxwpoq6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/cjxwpoq6' target=\"_blank\">Augmented_Split5_EfficientNetB3_Transfer</a></strong> to <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3' target=\"_blank\">https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/cjxwpoq6' target=\"_blank\">https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/cjxwpoq6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>actual_epochs</td><td>â–</td></tr><tr><td>best_val_loss</td><td>â–</td></tr><tr><td>epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>learning_rate</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–</td></tr><tr><td>total_training_time</td><td>â–</td></tr><tr><td>train_accuracy</td><td>â–â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>train_loss</td><td>â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>val_accuracy</td><td>â–â–‚â–ƒâ–…â–„â–…â–†â–‡â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡</td></tr><tr><td>val_loss</td><td>â–ˆâ–‡â–…â–„â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–â–â–‚â–‚â–‚â–â–â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–‚</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>actual_epochs</td><td>50</td></tr><tr><td>best_val_loss</td><td>0.32322</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>total_training_time</td><td>1912.14667</td></tr><tr><td>train_accuracy</td><td>83.97473</td></tr><tr><td>train_loss</td><td>0.39951</td></tr><tr><td>val_accuracy</td><td>86.57501</td></tr><tr><td>val_loss</td><td>0.33577</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Augmented_Split5_EfficientNetB3_Transfer</strong> at: <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/cjxwpoq6' target=\"_blank\">https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/cjxwpoq6</a><br> View project at: <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3' target=\"_blank\">https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250731_011849-cjxwpoq6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/wanchalerm/pyNotebooks/wandb/run-20250731_015045-6lfzqtyw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/6lfzqtyw' target=\"_blank\">Augmented_Split5_EfficientNetB3_Retrain</a></strong> to <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3' target=\"_blank\">https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/6lfzqtyw' target=\"_blank\">https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/6lfzqtyw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 76\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>actual_epochs</td><td>â–</td></tr><tr><td>best_val_loss</td><td>â–</td></tr><tr><td>epoch</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>learning_rate</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–</td></tr><tr><td>total_training_time</td><td>â–</td></tr><tr><td>train_accuracy</td><td>â–â–„â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>train_loss</td><td>â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>val_accuracy</td><td>â–â–„â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆ</td></tr><tr><td>val_loss</td><td>â–ˆâ–„â–‚â–„â–‚â–â–‚â–â–‚â–ƒâ–‚â–â–‚â–â–‚â–â–‚â–‚â–â–ƒâ–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>actual_epochs</td><td>77</td></tr><tr><td>best_val_loss</td><td>0.0066</td></tr><tr><td>epoch</td><td>76</td></tr><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>total_training_time</td><td>7920.74207</td></tr><tr><td>train_accuracy</td><td>100</td></tr><tr><td>train_loss</td><td>3e-05</td></tr><tr><td>val_accuracy</td><td>99.77644</td></tr><tr><td>val_loss</td><td>0.01606</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Augmented_Split5_EfficientNetB3_Retrain</strong> at: <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/6lfzqtyw' target=\"_blank\">https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/6lfzqtyw</a><br> View project at: <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3' target=\"_blank\">https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250731_015045-6lfzqtyw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/wanchalerm/pyNotebooks/wandb/run-20250731_040248-xrrjt2pk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/xrrjt2pk' target=\"_blank\">Augmented_Split5_EfficientNetB3_Evaluation</a></strong> to <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3' target=\"_blank\">https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/xrrjt2pk' target=\"_blank\">https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/xrrjt2pk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>blurred_test_accuracy</td><td>â–</td></tr><tr><td>blurred_test_class0_accuracy</td><td>â–</td></tr><tr><td>blurred_test_class1_accuracy</td><td>â–</td></tr><tr><td>blurred_test_class2_accuracy</td><td>â–</td></tr><tr><td>blurred_test_class3_accuracy</td><td>â–</td></tr><tr><td>blurred_test_overall_accuracy</td><td>â–</td></tr><tr><td>test_accuracy</td><td>â–</td></tr><tr><td>test_class0_accuracy</td><td>â–</td></tr><tr><td>test_class1_accuracy</td><td>â–</td></tr><tr><td>test_class2_accuracy</td><td>â–</td></tr><tr><td>test_class3_accuracy</td><td>â–</td></tr><tr><td>test_overall_accuracy</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>blurred_test_accuracy</td><td>91.67779</td></tr><tr><td>blurred_test_class0_accuracy</td><td>82.13058</td></tr><tr><td>blurred_test_class1_accuracy</td><td>95.94595</td></tr><tr><td>blurred_test_class2_accuracy</td><td>95.07168</td></tr><tr><td>blurred_test_class3_accuracy</td><td>94.02174</td></tr><tr><td>blurred_test_overall_accuracy</td><td>91.67779</td></tr><tr><td>test_accuracy</td><td>99.86649</td></tr><tr><td>test_class0_accuracy</td><td>100</td></tr><tr><td>test_class1_accuracy</td><td>99.54955</td></tr><tr><td>test_class2_accuracy</td><td>100</td></tr><tr><td>test_class3_accuracy</td><td>99.90942</td></tr><tr><td>test_overall_accuracy</td><td>99.86649</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Augmented_Split5_EfficientNetB3_Evaluation</strong> at: <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/xrrjt2pk' target=\"_blank\">https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3/runs/xrrjt2pk</a><br> View project at: <a href='https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3' target=\"_blank\">https://wandb.ai/wanchp-chulalongkorn-university/MosquitoLarvae-Classification-All3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250731_040248-xrrjt2pk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Cell finished in 6h 28m 20.13s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ensure reproducibility when running the script\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # Run main training pipeline\n",
    "    main()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "034dcc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Cell started at: 2025-07-31 04:02:59\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Save results to CSV\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m results_df = pd.DataFrame(\u001b[43mresults\u001b[49m)\n\u001b[32m      3\u001b[39m results_df.to_csv(\u001b[33m'\u001b[39m\u001b[33mresults_1percent.csv\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Generate summary report\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'results' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Cell finished in 0.07 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save results to CSV\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('results_1percent.csv', index=False)\n",
    "\n",
    "# Generate summary report\n",
    "generate_summary_report(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10d0a3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Cell started at: 2025-08-22 15:28:35\n",
      "2.7.0+cu128\n",
      "8.3.166\n",
      "0.21.0\n",
      "âœ… Cell finished in 0.00 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "import ultralytics\n",
    "print(ultralytics.__version__)\n",
    "import wandb\n",
    "print(wandb.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultra-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
